{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一章 统计学习及监督学习概论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 统计学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "统计学习的三要素，简称为模型（model）,策略（strategy）和算法（algorithm）\n",
    "\n",
    "实现统计学习方法的步骤如下：\n",
    "\n",
    "（1）得到一个有限的训练数据集合；\n",
    "\n",
    "（2）确定包含所有可能的模型的假设空间，即学习模型的集合\n",
    "\n",
    "（3）确定模型选择的准则，即学习的策略\n",
    "\n",
    "（4）实现求解最优模型的算法，即学习的算法；\n",
    "\n",
    "（5）通过学习方法选择最优模型；\n",
    "\n",
    "（6）利用学习的最优模型对新数据进行预测或分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 统计学习的分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "统计学习或机器学习一般包括监督学习，无监督学习，强化学习。有时还包括半监督学习，主动学习。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基本分类\n",
    "#### 1.监督学习\n",
    "监督学习（supervised learning）利用训练数据集学习一个模型，再用模型对测试样本集进行预测。由于在这个过程中需要标注的训练数据集往往是人工给出的，所以称为监督学习，监督学习分为学习和预测两个过程，由学习系统与预测系统完成。\n",
    "\n",
    "#### 2.无监督学习\n",
    "无监督学习（unsupervised learning）是指从无标注数据中学习预测模型的机器学习问题。无标注数据是自然得到的数据，预测模型表示数据的类别，转换或概率。\n",
    "\n",
    "#### 3.强化学习\n",
    "强化学习（reinforcement learning）是指智能系统在与环境的连续互动中学习最优行为策略的机器学习问题。假设智能系统与环境的互动基于马尔科夫决策过程（Markov decision process），智能系统能观测到的是与环境互动得到的数据序列。强化学习的本质是学习最优的序贯策略。\n",
    "\n",
    "#### 4.半监督学习与主动学习 \n",
    "半监督学习（semi-supervised learning）是指利用标注数据和未标注数据学习预测模型的机器学习问题。通常有少量标注数据，大量未标注数据。\n",
    "\n",
    "#### 5.主动学习\n",
    "主动学习（active learning）是指机器不断主动给出实例进行主动标注，然后利用标注数据学习预测模型的机器学习问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 统计学习方法三要素\n",
    "### 1.3.1 模型\n",
    "监督学习中，模型就是所要学习的条件概率分布或决策函数。模型的假设空间（hypothesis space）包含所有可能的条件概率分布或决策函数。\n",
    "\n",
    "假设空间 $\\mathscr{F}$可以定义为决策函数的集合：\n",
    "\n",
    "$\\mathscr{F} = \\{f|Y=f(X)\\}$\n",
    "\n",
    "其中，X和Y是定义在输入空间$\\mathscr{X}$和输出空间$\\mathscr{Y}$上的变量，$\\mathscr{F}$通常是由一个参数向量决定的函数族：\n",
    "\n",
    "$\\mathscr{F} = \\{f|Y=f_\\theta(X),\\theta \\in \\mathbb{R}^n\\}$\n",
    "\n",
    "参数$\\theta$取值于n维欧式空间$\\mathbb{R}^n$，成为参数空间（parameter space）。\n",
    "\n",
    "同样的，假设空间也可以定义为条件概率的集合：\n",
    "\n",
    "$\\mathscr{F} = \\{P|P_\\theta(Y|X),\\theta \\in \\mathbb{R}^n\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 策略\n",
    "#### 1.损失函数和风险函数\n",
    "监督学习问题是在假设空间$\\mathscr{F}$中选取模型$f$作为决策函数，对于给定的输入$X$，由$f(X)$给出相应的输出$Y$，用一个损失函数（loss function）或代价函数（cost function）来度量预测错误的程度。损失函数$f(X)$和$Y$的非负实值函数，即为$L(Y,f(X))$\n",
    "\n",
    "统计学习常用的损失函数有以下几种：\n",
    "\n",
    "（1）0-1损失函数（0-1 loss function）\n",
    "\n",
    "$L(Y,f(X)）=\\left\\{\\begin{matrix} 1,\\quad Y\\neq f(X)\n",
    "\\\\ 0,\\quad Y = f(X)\n",
    "\\end{matrix}\\right.$\n",
    "\n",
    "（2）平方损失函数（quadratic loss function）\n",
    "\n",
    "$L(Y,f(X))=(Y-f(X))^2$\n",
    "\n",
    "（3）绝对损失函数（absolute loss function）\n",
    "\n",
    "$L(Y,f(X)) = |Y-f(X)|$\n",
    "\n",
    "（4）对数损失函数（logarithmic loss function）\n",
    "\n",
    "$L(Y,P(Y|X)) = -logP(Y|X)$\n",
    "\n",
    "损失函数值越小，模型就越好，损失函数的期望：\n",
    "\n",
    "$R_{exp}(f)=E_P[L(Y,f(X))]=\\int_{\\mathcal{X}\\times \\mathcal{Y}}L(y,f(x))P(x,y)dxdy$\n",
    "\n",
    "称为风险函数（risk function）或期望损失（expected loss）\n",
    "\n",
    "对于给定训练数据集，模型$f(X)$关于训练数据集的平均损失成为经验风险（empirical risk）或经验损失（empirical loss），记作$R_{emp}$\n",
    "\n",
    "$R_{emp}(f) = \\frac{1}{N}\\Sigma_{i=1}^N L(y_i,f(x_i))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.经验风险最小化与结构风险最小化\n",
    "经验风险最小化：\n",
    "\n",
    "$$\\mathop{\\min}_{f \\in \\mathscr{F}}\\frac{1}{N}\\sum^N_{i=1}L(y_i,f(x_i))$$\n",
    "\n",
    "结构风险最小化：\n",
    "\n",
    "$$R_{srm}(f)=\\frac{1}{N}\\sum^N_{i=1}L(y_i,f(x_i))+\\lambda J(f)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 正则化和交叉验证\n",
    "### 1.5.2 交叉验证\n",
    "#### 1.简单交叉验证\n",
    "将数据集随机的分为两部分，一部分作为训练集，另一部分作为测试集，然后通过不同参数个数下训练得到不同的模型，通过评价各个模型的测试误差，选出测试误差最小的模型\n",
    "\n",
    "#### 2.S折交叉验证（S-fold cross validation）\n",
    "随机地将已给数据切分为S个互不相交，大小相同的子集，然后利用S-1个子集的数据训练模型，用余下的子集测试模型，选出S次评测中平均测试误差最小的模型。\n",
    "\n",
    "#### 3.留一交叉验证\n",
    "S折交叉验证中S=N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 生成模型与判别模型\n",
    "生成模型（generative model）：由数据学习联合概率分布$P(X,Y)$，然后求出条件概率分布$P(Y|X)$作为预测的模型，即生成模型。例如朴素贝叶斯法和隐马尔科夫模型。\n",
    "判别模型（discriminative model）：通过学习决策函数$f(X)$或者条件概率分布$P(Y|X)$作为预测模型，判断输入X时，应该输出什么样的Y，即判别模型。例如k近邻法，感知机，决策树，逻辑回归，最大熵模型等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 习题解答\n",
    "### 1.1\n",
    "伯努利模型（Bernoulli Model）：$P(X=1)=p$\n",
    "\n",
    "似然函数$L(p|k)=P(X=k|p)=p^k(1-p)^{n-k}$\n",
    "\n",
    "考虑对数似然函数$ln L(p|k) = kln(p)+(n-k)ln(1-p)$\n",
    "\n",
    "$\\frac{\\partial ln L(p|k)}{\\partial p} = \\frac{k}{p}-\\frac{n-k}{1-p} = \\frac{k-np}{p(1-p)}$\n",
    "\n",
    "在$p=\\frac{k}{n}时，对数似然函数取得最大值$\n",
    "\n",
    "三要素：\n",
    "\n",
    "模型：伯努利模型\n",
    "\n",
    "策略：选择对数似然损失函数，经验风险最小化\n",
    "\n",
    "算法：显式解析解\n",
    "\n",
    "贝叶斯估计（最大后验概率估计）：\n",
    "\n",
    "$P(\\theta|D) = \\frac{P(\\theta)P(D|\\theta)}{P(D)}$\n",
    "\n",
    "$P(D|\\theta)$为似然函数,$P(D|\\theta)=\\theta^k(1-\\theta)^{n-k}$\n",
    "\n",
    "先验知识：如在先前的数据中已经出现了$\\alpha_h$次正面，$\\alpha_t$次反面。服从Beta分布，$E(X)=\\frac{\\alpha_h}{\\alpha_h+\\alpha_t}$\n",
    "\n",
    "$P(\\theta|\\alpha_h,\\alpha_t)=\\frac{1}{B(\\alpha_h,\\alpha_t)}\\theta^{\\alpha_h-1}(1-\\theta)^{\\alpha_t-1}$\n",
    "\n",
    "得到后验分布$P(\\theta|D) \\propto \\frac{1}{B(\\alpha_h,\\alpha_t)}\\theta^{\\alpha_h+k-1}(1-\\theta)^{\\alpha_t+n-k-1}\\propto \\theta^{\\alpha_h+k-1}(1-\\theta)^{\\alpha_t+n-k-1}$\n",
    "\n",
    "通过最大化后验概率,得到$\\theta = \\frac{\\alpha_h+k-1}{\\alpha_h+\\alpha_t+n-2}$\n",
    "\n",
    "三要素：\n",
    "\n",
    "模型：伯努利模型\n",
    "\n",
    "策略：结构性风险最小化\n",
    "\n",
    "算法：显式解析解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2\n",
    "模型：条件概率分布\n",
    "\n",
    "损失函数：对数似然函数，经验风险最小化\n",
    "\n",
    "$$\\mathop{\\min}_{f \\in \\mathscr{F}}\\frac{1}{N}\\sum^N_{i=1}L(y_i,f(x_i))= - \\mathop{\\min}_{f \\in \\mathscr{F}}\\frac{1}{N}\\sum^N_{i=1}log P(Y_i|X_i)=\\mathop{\\max}_{f \\in \\mathscr{F}}\\frac{1}{N}\\sum^N_{i=1}log P(Y_i|X_i)$$\n",
    "\n",
    "极大似然估计（对数似然函数）：\n",
    "\n",
    "$log (Y_1,Y_2,…,Y_n|X_1,X_2,…,X_n,\\theta)=log(\\prod^n_{i=1} P(Y_i|X_i,\\theta))=\\sum^n_{i=1}log P(Y_i|X_i,\\theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
