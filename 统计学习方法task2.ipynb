{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二章 感知机\n",
    "## 2.1 感知机模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**定义2.1（感知机）**  假设输入空间（特征空间）是$\\mathcal{X} \\subseteq \\mathbb(R)^n$，输出空间是$\\mathcal{Y}={+1,-1}$，输入$x \\in \\mathcal{X}$表示实例的特征向量，对应于输入空间（特征空间）的点；输出$y \\in \\mathcal{Y}$表示实例的类别。由输入空间到输出空间的如下函数：\n",
    "$$f(x)=sign(w\\cdot x+b)$$\n",
    "称为感知机。其中$w$和$b$为感知机模型参数，$w \\in \\mathbb{R}^n$叫做权值（weight）或权值向量（weight vector），$b \\in \\mathbb{R}$叫做偏置（bias），$w\\cdot x$表示$w$和$x$的内积。sign是符号函数。\n",
    "\n",
    "感知机是一种线性分类模型，属于判别模型。感知机模型的假设空间定义在特征空间中的所有线性分类模型（linear classification model）或线性分类器（linear classifier）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 感知机学习策略\n",
    "假设超平面S的所有误分类点的集合为M，所有误分类点到超平面S的总距离为：\n",
    "$$-\\frac{1}{\\| w\\|}\\sum_{x_i\\in M}y_i(w\\cdot x_i+b)$$\n",
    "忽略$\\frac{1}{\\| w\\|}$得到感知机学习的损失函数。\n",
    "\n",
    "感知机$sign(w\\cdot x+b)$的损失函数（经验风险函数）定义为：\n",
    "$$L(w,b)=-\\sum_{x_i\\in M}y_i(w\\cdot x_i+b)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2.3 感知机学习算法\n",
    "对给定的训练集$T={(x_1,y_1),(x_2,y_2),…,(x_N,y_N)}$，其中$x_i \\in \\mathcal{X}=\\mathbb{R}^n$，$y_i \\in \\mathcal{Y}={-1,1}$，$i=1,2,…,N$，求参数$w$，$b$，使其为下述损失函数极小化的解\n",
    "$$\\mathop{\\min}_{w,b}L(w,b)=-\\sum_{x_i\\in M}y_i(w\\cdot x_i+b)$$\n",
    "采用随机梯度下降法（stochastic gradient descent）\n",
    "\n",
    "假设误分类点M是固定的，损失函数$L(w,b)$的梯度由\n",
    "$$\\triangledown_wL(w,b)=-\\sum_{x_i\\in M}y_ix_i$$\n",
    "$$\\triangledown_bL(w,b)=-\\sum_{x_i\\in M}y_i$$\n",
    "随机选取一个误分类点$(x_i,y_i)$，对$w$,$b$进行更新：\n",
    "$$w\\leftarrow w+\\eta y_ix_i$$\n",
    "$$b\\leftarrow b+\\eta y_i$$\n",
    "其中$\\eta$（$0<\\eta\\leqslant 1$）是步长，统计学习中又称为学习率（learning rate）。通过迭代可以是损失函数不断减小，直到为0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 感知机学习算法的对偶形式\n",
    "对偶形式的基本想法是，将$w$和$b$表示为实例$x_i$和标记$y_i$的线性组合形式，通过求解其系数而求得$w$和$b$。不失一般性，假设$w$和$b$的初始值均为0。通过对误分类点$(x_i,y_i)$逐步修改$w$和$b$，假设经过n次修改，$w$和$b$关于$(x_i,y_i)$的增量分别为$\\alpha_iy_ix_i$和$\\alpha_iy_i$，这里$\\alpha_i = n_i\\eta$，最后学习到的$w$，$b$可以分别表示为：\n",
    "$$w=\\sum_{i=1}^N\\alpha_iy_ix_i$$\n",
    "$$b=\\sum_{i=1}^N\\alpha_iy_i$$\n",
    "这里，$\\alpha_i\\geqslant 0,i=1,2,…,N$，当$\\eta=1$时，表示第i个实例点由于误分而进行更新的次数，实例点更新次数越多，意味着距离超平面越近，越难正确分类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 算法2.2（感知机算法的对偶形式）\n",
    "输入：线性可分的数据集$T={(x_i,y_1),(x_2,y_2),…,(x_N,y_N)}$,其中$x_i \\in \\mathbb{R}^n,y_i\\in{-1,+1},i=1,2,…,N$；学习率$\\eta(0<\\eta\\leqslant 1)$\n",
    "\n",
    "输出：$\\alpha,b$：感知机模型$f(x)=sign(\\sum_{j=1}^N\\alpha_jy_jx_j\\cdot x+b)$，其中$\\alpha = (\\alpha_1,\\alpha_2,…,\\alpha_N)^T$。\n",
    "\n",
    "（1）$\\alpha\\leftarrow0,b\\leftarrow0$\n",
    "\n",
    "（2）在训练集中选取数据$(x_i,y_i)$；\n",
    "\n",
    "（3）如果$y_i(\\sum_{j=1}^N\\alpha_jy_jx_j\\cdot x_i+b)\\leqslant 0$，\n",
    "$$\\alpha_i\\leftarrow\\alpha_i+eta$$\n",
    "$$b\\leftarrow b+\\eta y_i$$\n",
    "\n",
    "（4）转至（2）直到没有误分类数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 习题\n",
    "### 2.1 \n",
    "对于异或（XOR）,$x_1=(1,1),y_1=-1;x_2=(1,0),y_2=1;x_3=(0,1),y_3=1;x_4=(0,0),y_4=-1$。\n",
    "若存在感知机模型满足，即存在$w$和$b$，使得$y_i(w \\cdot x_i+b)>0,i=1,2,3,4$\n",
    "即:\n",
    "$$w_1+w_2+b<0$$\n",
    "$$w_1+b>0$$\n",
    "$$w_2+b>0$$\n",
    "$$b<0$$\n",
    "将上式1,4与2,3分别相加可得矛盾。因此感知机无法表示异或"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2\n",
    "正实例点$x_1=(1,2)^T,x_2=(2,3)^T$，负实例点$x_3=(2,1)^T,x_4=(3,-1)^T$\n",
    "采用对偶形式求解，Gram矩阵为：\n",
    "$$\\mathbb{G}=|x_i\\cdot x_j|=\\begin{bmatrix}\n",
    "5&8&4&1\\\\\n",
    "8&13&7&3\\\\\n",
    "4&7&5&5\\\\\n",
    "1&3&5&10\n",
    "\\end{bmatrix}$$\n",
    "求解迭代过程如下：\n",
    "\n",
    "|k  | 0 |1|2|\n",
    "|----|----|----|----|\n",
    "|||$x_1$|$x_3$|\n",
    "|$\\alpha_1$|0|1|0|\n",
    "|$\\alpha_2$|0|0|0|\n",
    "|$\\alpha_3$|0|0|1|\n",
    "|$\\alpha_4$|0|0|0|\n",
    "|$b$|0|1|0|\n",
    "\n",
    "得到的感知机模型为:\n",
    "$$f(x)=sign(-x^{(1)}+x^{(2)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数：0\n",
      "误分点为：x0\n",
      "[0 0 0 0]\n",
      "0\n",
      "0\n",
      "___________________\n",
      "迭代次数：1\n",
      "误分点为：x2\n",
      "[1 0 0 0]\n",
      "1\n",
      "-8\n",
      "___________________\n",
      "[-1  1]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x=np.array([[1,2],[2,3],[2,1],[3,-1]])\n",
    "y=np.array([1,1,-1,-1])\n",
    "a=np.array([0,0,0,0])\n",
    "b=0\n",
    "res=0\n",
    "j=0\n",
    "inp=np.array([a[0]*y[0]*x[0],a[1]*y[1]*x[1],a[2]*y[2]*x[2],a[3]*y[3]*x[3]])\n",
    "times=0\n",
    "while j<4:\n",
    "    print(\"迭代次数：\"+str(times))\n",
    "    print(\"误分点为：x\"+str(j))\n",
    "    print(a)\n",
    "    print(b)\n",
    "    print(res)\n",
    "    print(\"___________________\")\n",
    "    a[j]+=1\n",
    "    b+=y[j]\n",
    "    j=0\n",
    "    times+=1\n",
    "    for k in range(4):\n",
    "        inp[k]=a[k]*y[k]*x[k]\n",
    "    while j <4:\n",
    "        res = y[j]*(sum(np.sum(inp*np.array([x[j],x[j],x[j],x[j]]),axis=1)+b))\n",
    "        if res>0:\n",
    "            j+=1\n",
    "        else:\n",
    "            break\n",
    "inp=np.array([a[0]*y[0]*x[0],a[1]*y[1]*x[1],a[2]*y[2]*x[2],a[3]*y[3]*x[3]])\n",
    "print(np.sum(inp,axis=0))\n",
    "print(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
